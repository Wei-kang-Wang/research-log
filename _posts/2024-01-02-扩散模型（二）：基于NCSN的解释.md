---
layout: post
comments: True
title: "扩散模型（二）：基于NCSN的解释"
date: 2024-01-02 02:09:00
tag: diffusion

---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

noise-conditioned score network，简称NCSN，在2019年由宋飏等人提出，是早于DDPM的，但是由于形式更为复杂，所以并没有火起来，直到后来人们才发现，其蕴含着比DDPM更深刻的原理（实际上DDPM可以看作NCSN的一种特例）。而之后，宋飏又在ICLR2021上发表了[https://arxiv.org/pdf/2011.13456](https://arxiv.org/pdf/2011.13456)用来在SDE框架下解释DDPM和NCSN的统一性。

NCSN，或者更广泛一点说，scored-based generative model这一类模型，的优点有：
* 可以有媲美GAN的生成质量，但无需对抗训练，从而避免了类似于GAN那种训练困境
* 灵活的模型框架选择，无需像flow-based models那样，只能选择可以表示invertible transformation的框架

## 1. 从生成模型到score-based model

### (1). 生成模型

从一个未知的数据分布$$p(x)$$中，独立的采样出了一系列的样本$$\lbrace x_1, \cdots x_N \rbrace$$，这些既是数据集。而生成模型的目的就是，从这个含有有限样本的数据集出发，去拟合数据背后的分布$$p(x)$$，从而就可以获得无穷无尽的样本了。

为了实现从数据集估计其分布$$p(x)$$的目标，首先需要去对$$p(x)$$进行建模。而最常见的建模方式就是parametric模型，即首先选择一类概率分布并且认为其覆盖了$$p(x)$$，用带参数的分布$$p_{\theta}(x)$$来表示这一簇分布。而我们的目的，则是从数据集来估计这个参数$$\theta$$，从而得到$$p_{\theta^{\ast}}(x) \approx p(x)$$。

而很多时候，我们都是用energy-based的方法来表示$$p_{\theta}(x)$$，即

$$p_{\theta}(x) = e^{-f_{\theta}(x)} / Z_{\theta}$$

其中$$f_{\theta}(x) \in \mathbb{R}$$是任意的以$$\theta$$为参数的函数，而与$$x$$无关但与$$\theta$$有关的$$Z_{\theta}$$则是归一化常数，用来获得最终的分布$$p_{\theta}(x)$$。

最常见的对数据集的拟合方式就是使用最大似然估计：

$$\theta^{\ast} = \arg\max\limits_{\theta} \sum_{i=1}^N log p_{\theta}(x_i) = \arg\min\limits_{\theta} NlogZ_{\theta} + \sum_{i=1}^N f_{\theta}(x_i)$$

但是由上面的式子可以看到，objective function里含有$$Z_{\theta}$$，而这个值往往是难以估计的。

为了解决这个问题，宋飏等人提出了score-based model，其基本思想是，与其对$$p(x)$$建模，不如对$$p(x)$$对数据$$x$$的梯度进行建模来间接获取数据分布$$p(x)$$，因为$$Z_{\theta}$$与$$x$$无关，所以其关于$$x$$的梯度就是0，从而就可以避免对$$Z_{\theta}$$进行估计。


### (2). score-based model

score function，或者称为score，也就是NCSN那篇论文标题中的gradients of the data distribution，具体来说是概率密度函数对数的梯度：$$\nabla_x log p(x)$$。而用来对score进行建模/拟合的模型，就叫做score-based model，记这类模型为$$s_{\theta}(x)$$，其中$$\theta$$是模型可学习参数。

和直接建模数据分布函数$$p(x)$$不同，score-based model并不会受到归一化系数$$Z_{\theta}$$的影响。如果使用energy-based model来建模$$p(x)$$的化，那么$$s_{\theta}(x) = \nabla_x log p_{\theta}(x) = \nabla_x (-f_{\theta}(x) - log Z_{\theta}) = -\nabla_x f_{\theta}(x)$$。这样的话，我们就可以使用各种灵活的模型，而不需要考虑归一化参数是否容易求解这样一个巨大的制约了。

score的物理意义是：对于每个点$$x$$来说，该点的score就是数据的对数概率密度函数在该点$$x$$增长最快的方向

![4]({{ '/assets/images/diffusion_4.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[DiffusionModel-NCSN原理与推导](https://zhuanlan.zhihu.com/p/670052757)*

上图可视化了一个2维分布概率密度函数对数的梯度（在每个点都有方向和大小，因为梯度是个向量）。如图所示，图里有两个中心，而这即代表了$$log p_{\theta}(x)$$取极大值的地方，即最能代表此数据先验分布的区域。对于生成模型而言，我们期望生成的数据，就应该位于这些数据先验分布值大的区域。所以说如果我们可以估计score，在有了score之后，就可以利用score来确定$$p_{\theta}(x)$$极大值的方位，从而就可以有更理想的生成结果。而在有score的情况下，从任意点出发，到达$$p_{\theta}(x)$$某个极大值的方法，就是朗之万采样（Langevin Sampling）。

### (3). Langevin采样

假设我们已经有了一个训练好的score-based model $$s_{\theta}(x)$$，可以对于任意输入的$$x$$，输出该点的score了，那么该如何采样，才能靠近$$p_{\theta}(x)$$的极大值点呢？

这实际上是一个Langevin dynamics问题（朗之万动力学），其提供了一种仅利用某个分布$$p(x)$$的score function，即$$\nabla_x log p(x)$$（对数概率密度函数的梯度），就可以对分布$$p(x)$$进行采样的MCMC方法。其具体操作如下：

* 首先从任意的某个先验分布，比如Uniform分布或者高斯分布中，随机采样一个初始样本$$x_0 \sim \pi(x)$$
* 利用如下公式逐渐将样本像$$p(x)$$的高密度区域靠近：

$$ x_{i+1} \leftarrow x_i + \epsilon \nabla_x log p(x_i) + \sqrt{2 \epsilon} z_i, \  \text{where} \  z_i \sim \mathcal{N}(\mathbf{0}, \mathbf{I}), i=1,2,\cdots, K$$

* 当步长$$\epsilon \rightarrow 0, K \rightarrow \infty$$时，$$x_k \sim p(x)$$

在实际操作中，使用训练好的score function model $$s_{\theta}(x)$$替代上面的$$\nabla_x log p(x)$$，并且取足够小的$$\epsilon$$采样足够多次，这样就可以保证在某次之后的采样值，均服从$$p(x)$$分布。这个过程就叫做Langevin采样。

### (4). score matching

朗之万采样解决了我们在有了score之后，该如何采样样本，使其服从$$p(x)$$分布的问题，而最重要的是如何获取score呢？score-based model的方法是训练一个score-based model来逼近score。训练方法如下所述。

首先写出损失函数（目标函数）。score-based model和似然函数模型类似，也是将最小化模型和数据分布之间的Fisher divergence作为训练的目标：

$$\mathop{\mathbb{E}}_{p(x)} \left[ \lVert \nabla_x log p(x) - s_{\theta}(x) \rVert_2^2 \right] = \int p(x) \lVert \nabla_x log p(x) - s_{\theta}(x) \rVert_2^2 dx$$

但$$p(x)$$是未知的，所以上述式子无法计算，所以实际上，是利用经验分布$$p_{data}(x)$$（即从数据中获得的分布）来代替真实分布$$p(x)$$来计算的，从而我们的目标函数如下：

$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 \right] = \int p_{data}(x) \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 dx$$

经验分布和真实分布的差别可以看[这篇博客](https://blog.csdn.net/qq_44638724/article/details/120242712)

而基于上述目标函数，使得模型的score-function与根据数据得到的经验分布的score相matching的算法，就叫做score-matching算法。

首先，我们简化一下上述目标函数：

$$
\begin{align}
& \mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 \right] \propto \frac{1}{2} \mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert s_{\theta}(x) - \frac{\partial log p_{data}(x)}{\partial x} \rVert_2^2 \right] \\
&= \frac{1}{2} \int p_{data}(x) \left[ \Vert s_{\theta}(x) \rVert_2^2 + \lVert \frac{\partial log p_{data}(x)}{\partial x} \rVert_2^2 - 2(\frac{\partial log p_{data}(x)}{\partial x})^Ts_{\theta}(x) \right] dx
\end{align}
$$

而

$$
\begin{align}
& \int p_{data}(x) \left[- 2(\frac{\partial log p_{data}(x)}{\partial x})^Ts_{\theta}(x) \right] dx = -2 \int p_{data}(x) (\sum_{i=1}^N \frac{\partial log p_{data}(x)}{\partial x_i})s_{\theta}(x)_i) dx \\
&= -2 \sum_{i=1}^N \int p_{data}(x) \frac{1}{p_{data}(x)} \frac{\partial p_{data}(x)}{\partial x_i} s_{\theta}(x)_i dx = -2 \sum_{i=1}^N \int \frac{\partial p_{data}(x)}{\partial x_i} s_{\theta}(x)_i dx \\
&= -2 \sum_{i=1}^N \int (\frac{\partial(p_{data}(x) s_{\theta}(x)_i)}{\partial x_i} - p_{data}(x) \frac{\partial s_{\theta}(x)_i}{\partial x_i}) dx = -2 \sum_{i=1}^N (p_{data}(x) s_{\theta}(x)_i \vert_{-\infty}^{\infty} - \int p_{data}(x) \frac{\partial s_{\theta}(x)_i}{\partial x_i} dx) \\
&= 2 \sum_{i=1}^N \int p_{data}(x) \frac{\partial s_{\theta}(x)_i}{\partial x_i} dx = 2 \int \sum_{i=1}^N p_{data}(x) \frac{\partial s_{\theta}(x)_i}{\partial x_i} dx = 2 \int p_{data}(x) tr(\frac{s_{\theta}(x)}{\partial x})dx
\end{align}
$$

其中$$N$$是输入$$x$$的维度。

回到之前的目标函数，可以发现，$$\lVert \frac{\partial log p_{data}(x)}{\partial x} \rVert_2^2$$与$$\theta$$无关，从而，之前的目标函数可以简化为：

$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \frac{1}{2} \Vert s_{theta}(x) \rVert_2^2 + tr(\frac{s_{\theta}(x)}{\partial x}) \right] dx$$

目标函数得到了简化，但是如果表示$$s_{\theta}(x)$$的网络很深，$$x$$的维度很大的时候，计算$$tr(\frac{s_{\theta}(x)}{\partial x})$$仍然非常的繁重，在实际代码里部署起来很困难，从而在NCSN那篇论文里，又提出了两种更进一步的改进方法

**改进一：sliced score matching（由宋飏于2019年提出）**

在计算目标函数的时候，我们需要计算矩阵$$\frac{s_{\theta}(x)}{\partial x}$$的迹，而对于矩阵迹的估计，恰好有一种技巧：Hutchinson Trace estimation。

其具体做法是，对于一个随机向量$$v \in \mathbb{R}^n$$，如果其协方差矩阵为$$I$$，均值为$$\mathbf{0}$$，那么对于任意矩阵$$A \in \mathbb{R}^{n \times n}$$，$$tr(A) = tr(A \mathbb{E}(vv^T)) = \mathbb{E}(tr(A v v^T)) = \mathbb{E}(tr(v^T A v)) = \mathbb{E}(v^T A v)$$，从而将求矩阵$$A$$的迹，变成了求标量$$v^TAv$$对$$v$$的期望。

从而将上述技巧用到上述目标函数里，$$tr(\frac{s_{\theta}(x)}{\partial x}) = \mathbb{E}(v^T \frac{s_{\theta}(x)}{\partial x} v) = \mathbb{E}(v^T \frac{v^T s_{\theta}(x)}{\partial x})$$，目标函数则变为：

$$\mathop{\mathbb{E}}_{p(v), p_{data}(x)} \left[ \frac{1}{2} \Vert s_{\theta}(x) \rVert_2^2 + v^T \frac{v^T s_{\theta}(x)}{\partial x} \right]$$

而计算$$\frac{v^T s_{\theta}(x)}{\partial x}$$只需要计算$$N$$次（相较于之前的$$N^2$$次，减少了很多），但引入了一个新的期望需要进行采样估计，如果$$N$$很大的时候，这样的做法是有效的。

**改进二：denoising score matching（NCSN那篇论文里的方法）**

这个方法也是为了避免计算$$tr(\frac{s_{\theta}(x)}{\partial x})$$，但它直接回到了最初的目标函数$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 \right]$$，对于未知的$$p_{data}$$，其如果仅出现在求期望的概率分布上，并不出现在被求期望的值里面的时候，还是好办的，因为其就是经验概率分布，所以就是将所有的真实数据对应的被求期望的值加起来除以总数据数就行了（这也是为什么简化了的目标函数$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \frac{1}{2} \Vert s_{\theta}(x) \rVert_2^2 + tr(\frac{s_{\theta}(x)}{\partial x}) \right] dx$$可以计算的原因，这个目标函数的问题只是在于它太难算了）。但是如果$$p_{data}(x)$$同时也出现在了被求期望的值的内部，就不能按照上述方法算了，而如果我们回到了最初的目标函数，那么该目标函数的被求期望的值里就含有$$p_{data}(x)$$，所以需要想另一种办法解决这个问题，而denoising score matching的办法就是：既然$$p_{data}(x)$$未知，就自行定义一个已知的数据分布$$q_{\sigma}$$（比如高斯分布），而且假设这个分布是在$$p_{data}$$上加噪声得来的。

具体来说，记原数据为$$x$$，加噪之后的数据为$$\tilde{x}$$，我们定义$$q(\tilde{x} \vert x) = \mathcal{N}(\tilde{x}; x, \sigma^2 \textbf{I})$$，而且$$\sigma$$是已知的固定参数。从而$$q_{\sigma}(\tilde{x}) = \int q_{\sigma}(\tilde{x} \vert x) p_{data}(x) dx$$。我们希望用$$q_{\sigma}(\tilde{x})$$的score来近似$$p_{data}(x)$$的score（在$$\sigma$$很小的时候，它们是很相近的）。

那么对于这个新的数据$$\tilde{x}$$来说，其score-matching的目标函数就是:

$$\mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \lVert \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x}) - s_{\theta}(\tilde{x}) \rVert_2^2 \right]$$

这个式子可以显式的计算对于$$\tilde{x}$$score-matching算法的目标函数的值（因为$$q_{\sigma}(\tilde{x})$$显式的给定了），所以它叫做explicit score matching（ESM）。

$$\textbf{ESM} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \lVert s_{\theta}(\tilde{x}) \rVert_2^2 \right] - 2 \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \langle s_{\theta}(\tilde{x}), \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x}) \rangle \right] + c_1, \  \text{where} \  c_1 \  \text{is} \  \text{irrelavant} \   \text{w.r.t.} \  \theta$$

再定义一个denoising score matching（DSM）：

$$
\begin{align}
\textbf{DSM} &= \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x}, x)} \left[ \lVert s_{\theta}(\tilde{x}) \rVert_2^2 \right] - 2 \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x}, x)} \left[ \langle s_{\theta}(\tilde{x}), \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) \rangle \right] + c_2, \  \text{where} \  c_2 \  \text{is} \  \text{irrelavant} \   \text{w.r.t.} \  \theta
\end{align}
$$

而我们发现，$$\textbf{ESM}$$的第一项和$$\textbf{DSM}$$的第一项相等：

$$\mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \lVert s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \int_{\tilde{x}} q_{\sigma}(\tilde{x}) \lVert s_{\theta}(\tilde{x}) \rVert_2^2 d \tilde{x} = \int_{\tilde{x}} \int_{x} q_{\sigma}(\tilde{x} \vert x) p_{data}(x) \lVert s_{\theta}(\tilde{x}) \rVert_2^2 d \tilde{x} dx =  \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x}, x)} \left[ \lVert s_{\theta}(\tilde{x}) \rVert_2^2 \right]$$

以及$$\textbf{ESM}$$的第二项和$$\textbf{DSM}$$的第二项也相等：

$$
\begin{align}
\mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \langle s_{\theta}(\tilde{x}), \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x}) \rangle \right] &= \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x})} \left[ \langle s_{\theta}(\tilde{x}), \frac{\partial log q_{\sigma}(\tilde{x})}{\partial \tilde{x}} \rangle \right] = \int_{\tilde{x}} q_{\sigma}(\tilde{x}) \langle s_{\theta}(\tilde{x}), \frac{\partial log q_{\sigma}(\tilde{x})}{\partial \tilde{x}} \rangle d \tilde{x} = \int_{\tilde{x}} q_{\sigma}(\tilde{x}) \langle s_{\theta}(\tilde{x}), \frac{1}{q_{\sigma}(\partial \tilde{x})}\frac{\partial q_{\sigma}(\partial \tilde{x})}{\tilde{x}} \rangle d \tilde{x}\\
&= \int_{\tilde{x}} \langle s_{\theta}(\tilde{x}), \frac{\partial q_{\sigma}(\partial \tilde{x})}{\partial \tilde{x}} \rangle d \tilde{x} = \int_{\tilde{x}} \langle s_{\theta}(\tilde{x}), \frac{\partial}{\partial \tilde{x}} \int_x q_{\sigma}(\tilde{x} \vert x) p_{data}(x) dx \rangle d \tilde{x} = \int_{\tilde{x}} \langle s_{\theta}(\tilde{x}), \int_x \frac{\partial q_{\sigma}(\tilde{x} \vert x)}{\partial \tilde{x}} p_{data}(x) dx \rangle d \tilde{x}\\
&= \int_{\tilde{x}} \langle s_{\theta}(\tilde{x}), \int_x \frac{\partial log q_{\sigma}(\tilde{x} \vert x)}{\partial \tilde{x}} q_{\sigma}(\tilde{x} \vert x) p_{data}(x) dx \rangle d \tilde{x} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x}, x)} \left[ \langle s_{\theta}(\tilde{x}), \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) \rangle \right]
\end{align}
$$

从而惊讶地发现，ESM和DSM只相差了一个与$$\theta$$无关的常数。从而现在可以用DSM来替代ESM作为优化基于$$\tilde{x}$$的score-matching的目标函数了，也就是说，之前我们引入$$q_{\sigma}(\tilde{x})$$的score来近似$$p_{data}(x)$$的score，现在我们可以用$$q_{\sigma}(\tilde{x} \vert x)$$的score来近似$$p_{data}(x)$$的score了。而根据我们的假设，$$q_{\sigma}(\tilde{x} \vert x)$$就是一个高斯分布$$\mathcal{N}(\tilde{x}; x, \sigma^2 \textbf{I})$$，从而其score是可以closed-form计算出来的，也就是说，现在的目标函数变为：

$$\textbf{DSM} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{x-\tilde{x}}{\sigma^2} - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{-\epsilon}{\sigma^2} - s_{\theta}(\tilde{x}) \rVert_2^2 \right], \  \text{where} \  \epsilon \sim \mathcal{N}(\textbf{0}, \sigma^2 \textbf{I})$$

从而我们要做的就是，对于每个输入数据$$x$$，从$$\mathcal{N}(\textbf{0}, \sigma^2 \textbf{I})$$中采样噪声$$\epsilon$$，加到$$x$$上得到$$\tilde{x}$$，作为$$s_{\theta}$$的输入，然后优化上述目标函数，即DSM。也就是说，$$s_{\theta}$$实际上建模的是真实数据和加噪之后数据的差值（即噪声）。

综上，我们从概率分布的表示、估计到采样的过程基本已经完成了，整个“Score-based generative modeling”的过程可以总结如下图:

![5]({{ '/assets/images/diffusion_5.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[DiffusionModel-NCSN原理与推导](https://zhuanlan.zhihu.com/p/670052757)*

最后，再介绍一下score-based models的几个主要的问题。


### (5). score-based models的几个主要问题

尽管score-based models根据上述所说，具有完整的训练和采样过程（由score matching来对目标函数进行训练，由朗之万采样利用训练好的score function来对数据进行采样），但其在实际应用中有以下几个主要的困难：

* 目标函数难以优化，即loss难以收敛
* score matching算法对$$p_{data}(x)$$的score估计不准确
* 最终采样得到的数据，与训练数据的分布偏差较大

下面我们依次来看看这些问题并分析其原因。

**问题一：loss不易收敛**

如果我们采用sliced score matching方法，将简化后的目标函数$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \frac{1}{2} \Vert s_{theta}(x) \rVert_2^2 + tr(\frac{s_{\theta}(x)}{\partial x}) \right] dx$$，改进为$$\mathop{\mathbb{E}}_{p(v), p_{data}(x)} \left[ \frac{1}{2} \Vert s_{\theta}(x) \rVert_2^2 + v^T \frac{v^T s_{\theta}(x)}{\partial x} \right]$$，记为SSM loss，并对其进行优化，那么在实际操作中，该loss的变化趋势如下左图所示：

![6]({{ '/assets/images/diffusion_6.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[DiffusionModel-NCSN原理与推导](https://zhuanlan.zhihu.com/p/670052757)*

可以看到，SSM loss非常抖动。

为了解释这个现象，首先需要了解流行假设（manifold hypothesis）。

流行假设认为，生活中的真实数据大部分都倾向于分布在某个低维空间中（即用某几个自由参数就可以表示该空间）。也就是说，尽管针对数据的编码空间（比如说通过神经网络将数据表示为某种feature）的维度可能很大，但实际上该编码（feature）在很多维度上都存在信息冗余，所以实际上我们可以用更小的编码空间来表示这些数据，这说明实质上，这些数据仅仅分布在该高维编码空间的某个低维流形当中，并没有“占满”整个编码空间。

回到score-basde model上来，我们的数据同样也是位于某个低维流形之上（如果是图片的话，原始的编码空间即是像素空间，即$$\left[0,255\right]^{H \times W \times 3}$$），也就是说，数据并没有充满整个$$p(x)$$，即$$p_{data}(x)$$在很多$$x$$上是没有数据的，这就导致了在使用$$p_{data}(x)$$作为替代$$p(x)$$的真实分布的时候，这些$$x$$上的score是无法获得的。

> 而我们确实是需要使用$$p_{data}(x)$$来替代$$p(x)$$作为真实的数据分布，因为$$p(x)$$是完全无法知道的，我们有的只有数据！

而且对于sliced score matching，我们还将原始的目标函数$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \frac{1}{2} \Vert s_{theta}(x) \rVert_2^2 + tr(\frac{s_{\theta}(x)}{\partial x}) \right] dx$$，简化为了$$\mathop{\mathbb{E}}_{p(v), p_{data}(x)} \left[ \frac{1}{2} \Vert s_{\theta}(x) \rVert_2^2 + v^T \frac{v^T s_{\theta}(x)}{\partial x} \right]$$，该简化过程根据之前的推导，需要假设$$\lim_{x \rightarrow -\infty} p_{data}(x) = \lim_{x \rightarrow \infty} p_{data}(x) = 0$$，而着同样需要假设$$p_{data}(x)$$能够在整个编码空间上都有数据。

**问题二：score的估计不准确**

score的估计不准确，分为两个层面的不准确，首先是score function $$s_{\theta}(x)$$对于$$p_{data}(x)$$的score估计不准确，其次是$$s_{\theta}(x)$$对于真实分布$$p(x)$$的估计不准确。

对于后者来说，对于$$p(x)$$较小的区域，即概率密度较低的区域，数据集里位于该区域的数据数量会很少，甚至没有，这样的话，使用$$p_{data}(x)$$对$$p(x)$$进行近似的时候，在这些区域的近似就不准确。从训练的角度来说，score-based model在这些区域的值相对于真实的$$p(x)$$的score来说就估计的不准确（因为在这些区域，$$p_{data}(x)$$和$$p(x)$$的score本身就有较大的偏差，所以并不是score-matching算法或者是目标函数的问题，这是使用经验分布来替代真实分布造成的问题）。

而对于前者来说，从损失函数的角度来分析，损失函数为$$\mathop{\mathbb{E}}_{p_{data}(x)} \left[ \lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2 \right]$$，对于$$p_{data}(x)$$较小的区域，那么$$\lVert \nabla_x log p_{data}(x) - s_{\theta}(x) \rVert_2^2$$会乘上一个较小的$$p_{data}(x)$$权重，从而在整个loss里，这一项的比重很小，就会导致训练的时候不会关注这个区域，也就训练不充分，从而导致这个区域内的$$s_{\theta}(x)$$与$$\nabla_x log p_{data}(x)$$差异较大。

![8]({{ '/assets/images/diffusion_8.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}
*来自于[基于梯度去噪的分数模型：NCSN(Noise Conditional Score Networks)](https://zhuanlan.zhihu.com/p/597490389)*

对于上面图来说，左侧是$$p_{data}(x)$$的scores，右侧是训练好的模型，也就是score function，$$s_{\theta^{\ast}}(x)$$，其中深色的部分表示数据density大的部分，而红色框内部，则表示
$$p_{data}(x)$$的scores和$$s_{\theta^{\ast}}(x)$$相近的区域。可以看到，在density较低的区域，这两个scores是不相近的。


**问题三：生成结果偏差大**

如果分数估计不准，即$$s_{\theta}(x)$$与$$\nabla_{x} p(x)$$的偏差较大，那么一个直接的结果就是使用朗之万采样得到的新生成数据和数据集里的数据差异较大，即生成数据的分布，并不符合$$p(x)$$或者由数据集得到的经验分布$$p_{data}(x)$$。这是因为，对于朗之万采样过程来说，起始点很有可能会选择在一个低密度区域内，而由之前所说，低密度区域内$$s_{\theta}(x)$$不准确，从而导致每一步的方向都是不准确的，那么就很难保证更新后的采样点落在$$p(x)$$或者$$p_{data}(x)$$的高密度区域内。

另外一个令人惊讶的结果是，即使$$s_{\theta}(x)$$是准确的，即非常接近$$\nabla_x log p(x)$$，甚至直接用ground truth的$$\nabla_x log p(x)$$来作为朗之万采样的score，如果真实的数据分布$$p(x)$$是由多个分布按一定比例混合而成的，那么使用朗之万采样算法采样得到的结果，也不能反应各个分布之间的比例关系，下图给了一个例子：

![9]({{ '/assets/images/diffusion_9.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

上面的例子里，数据是由两个二维高斯分布混合而成的，左图是实际的数据分布$$p_{data}(x)$$，右图是根据真实的$$p(x)$$经过朗之万采样得到的数据分布。可以看到，朗之万采样的数据，并不能反映这这两个高斯分布在混合分布里所占的比例。

具体原因是，假设混合分布为$$p(x) = a p_1(x) + (1-a)p_2(x)$$，那么$$\nabla_x log p(x) = \nabla_x log p_1(x) + \nabla_x log p_2(x)$$，丢失了比例信息$$a$$。

> 实际上，如果朗之万采样算法里的步长$$\epsilon$$取得足够的小，时间$$T$$足够的长，那么实际上其采样值是可以逼近任意的数据分布的（包括混合分布），但是实际操作中，这两个值都是有限制的，就会导致上述的问题的发生。


而上述的三个问题，均可以用noise-conditioned score network（NCSN）解决。


## 2. NCSN

noise-conditioned score network是分数模型的一种

**训练目标**

使用不同强度（不同方差）零均值的采样的高斯噪声对原数据进行加噪（扰动），然后使用**同一个网络**，对加了不同级别**噪声的数据的分布的分数**，进行估计，这个网络的输入是加了噪声的数据，**以及噪声强度指示**。注意，是对加了噪声的数据分布的分数进行估计，而并不是对原数据分布的分数进行估计（因为做不到）。而在网络训练好了之后，对于加上强度足够小的噪声的数据的分布的分数，就近似于原数据的分布的分数。

**采样生成**

使用退火（annealing）朗之万方法使用score来采样。退火朗之万采样实际上就是在噪声强度递减的模式下进行朗之万采样。

NCSN是如何破解之前提到的score-based models的三个问题的：

* NCSN使用高斯噪声去扰动数据，而高斯噪声是弥散在整个编码空间中的，因此扰动后的数据就不在低维流形中了，从而score-matching算法就可以较好的训练$$s_{\theta}(x)$$去近似$$p_{data}(x)$$了。
* 在加上高斯噪声扰动数据时，尺度较大的噪声有希望将原数据从$$p(x)$$较高的区域转移到$$p(x)$$较低的区域，从而对低密度区域的数据也有了更多的训练。在低密度区域的数据量也增大之后，即使在朗之万采样的时候，初始值取在了低密度区域，但因为这个时候低密度区域也得到了良好的训练，所以$$s_{\theta}(x)$$在该区域的值也接近$$\nabla_x log p_{data}(x)$$的值，从而也可以在采样很多次后，到达高密度区域，也就是生成和原数据分布相似的图片。

NCSN是一类分数模型，所以之前所说的分数模型的目标函数，score-matching算法，以及在获得score function之后使用朗之万采样获取新数据的过程是一样的，但NCSN有另外的改进来缓解之前所说的score-based models的问题，下面我们具体来介绍这些改进的细节。

### (1). 噪声设计原理

NCSN使用了denoising score matching的方式来优化目标函数。按照之前所说的，对于每个输入的原数据$$x$$，我们对它加上一个噪声从而获得一个新的数据$$\tilde{x}$$，其分布满足：$$q(\tilde{x} \vert x) = \mathcal{N}(\tilde{x}; x, \sigma^2 \textbf{I})$$，其中$$\sigma$$是我们需要重点考虑的问题。

在NCSN中，我们实际上不仅仅考虑一个$$\sigma$$，而是考虑一系列的$$\sigma_i, i=1,2, \cdots, L$$，也就是说，对于一个数据$$x$$，会给他加上从不同的$$\mathcal{N}(\textbf{0}, \sigma_i^2 \textbf{I})$$里采样的噪声，得到一系列加噪的新数据$$\tilde{x}_i, i=1,2,\cdots, L$$。

那么，为什么要选择不同强度的噪声呢？

因为如果只选择一个的话，那么因为我们需要填充低密度区域，使得$$p_{data}(x)$$在这些区域也能有值，而且需要摆脱低维流形假设，那么$$\sigma^2$$就不能太小。但是另一方面，如果$$\sigma^2$$很大的话，从$$q_{\sigma}(\tilde{x} \vert x) = \mathcal{N}(\tilde{x}; x, \sigma^2 \textbf{I})$$可以看出，我们所采样的$$\tilde{x}$$就可能和$$x$$差距较大了，那这种情况下，用$$\nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x)$$来近似$$\nabla_{x} log p_{data}(x)$$就不合理了。

正是由于上述的这个矛盾，所以我们考虑一系列尺度的噪声，方差由大到小：$$\lbrace \sigma_i^2 \rbrace_{i=1}^L$$，并且满足$$\sigma_1 / \sigma_2 = \sigma_2 / \sigma_3 = \cdots = \sigma_{L-1} / \sigma_L > 1$$。并且$$\sigma_1$$要足够大，满足填充低密度区域且摆脱低维流形假设的需求，而$$\sigma_L$$要足够小，满足可以使用$$\nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x)$$来近似$$\nabla_{x} log p_{data}(x)$$的需求。

### (2). score拟合网络的设计

由于我们需要生成的数据和原输入数据具有相同的尺寸，所以选择U-Net作为网络的主体。输入是加了噪声之后的数据$$\tilde{x}$$，以及当前所加的噪声满足的高斯分布的方差$$\sigma$$，输出是对该加了噪声之后的数据$$\tilde{x}$$所满足的分布的对数的梯度的近似，即$$\nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x)$$。

而在有了网络结构，以及网络的输入输出之后，我们就可以考虑该如何训练这个网络了，NCSN采用的是denoising score matching算法。由之前的结果可知，对于单个噪声$$\mathcal{N}(\textbf{0}, \sigma^2 \textbf{I})$$，损失函数是DSM：

$$\textbf{DSM} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{x-\tilde{x}}{\sigma^2} - s_{\theta}(\tilde{x}) \rVert_2^2 \right] = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{-\epsilon}{\sigma^2} - s_{\theta}(\tilde{x}) \rVert_2^2 \right], \  \text{where} \  \epsilon \sim \mathcal{N}(\textbf{0}, \sigma^2 \textbf{I})$$

也就是：

$$\mathcal{L}(\theta, \sigma) = \textbf{DSM} = \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert \frac{x-\tilde{x}}{\sigma^2} - s_{\theta}(\tilde{x}, \sigma) \rVert_2^2 \right]$$

从而对于一系列的噪声$$\lbrace \sigma_i^2 \rbrace_{i=1}^L$$，网络的损失函数定义为：

$$\mathcal{L}(\theta, \lbrace \sigma_i^2 \rbrace_{i=1}^L) = \frac{1}{L} \sum_{i=1}^L \lambda_i (\sigma_i) \mathcal{L}(\theta, \sigma_i)$$

其中$$\lambda_i(\sigma_i)$$是依赖于$$\sigma_i$$的超参数，$$i=1,2,\cdots,L$$。

作者根据经验发现，在网络训练收敛之后，$$\lVert s_{\theta}(\tilde{x}, \sigma) \rVert_2$$的量级在$$\frac{1}{\sigma}$$附近，而作者希望所有的加权后的损失$$\lambda_i (\sigma_i) \mathcal{L}(\theta, \sigma_i)$$都有着差不多的量级，与$$\sigma_i$$的取值无关，从而设置$$\lambda_i = \sigma_i^2$$，从而：

$$\mathcal{L}(\theta, \lbrace \sigma_i^2 \rbrace_{i=1}^L) = \frac{1}{L} \sum_{i=1}^L \lambda_i (\sigma_i) \mathcal{L}(\theta, \sigma_i) = \frac{1}{L} \sum_{i=1}^L \mathop{\mathbb{E}}_{q_{\sigma}(\tilde{x} \vert x) p_{data}(x)} \left[ \lVert s_{\theta}(\tilde{x}_i, \sigma_i) + \epsilon_i \rVert_2^2 \right]$$

其中$$\epsilon_i \sim \mathcal{N}(\textbf{0}, \textbf{I})$$，$$\tilde{x}_i = x + \sigma_i \epsilon_i$$，$$i=1,2,\cdots, L$$。

> 这里的$$s_{\theta}$$的输入除了被扰动的数据$$\tilde{x}$$以外，还需要所加噪声对应高斯分布的方差作为输入，和之前DDPM里不仅需要$$x_t$$作为网络的输入，还需要$$t$$作为网络的输入，是等价的。

> 这里的$$s_{\theta}(\tilde{x}, \sigma)$$实际上是拟合了$$-\epsilon$$，也就是拟合了采样的噪声，和DDPM里$$\mu(x_t, t)$$实际上也是拟合了加在$$x_0$$上得到$$x_t$$的噪声$$\bar{\epsilon}_t$$是等价的。同样的，这里的噪声也是需要取多个强度的，也就是说，$$s_{\theta}$$也需要拟合多个强度的噪声。


### (3). 采样方法：退火朗之万采样（annealing Langevin dynamics

![10]({{ '/assets/images/diffusion_10.png' | relative_url }})
{: style="width: 1200px; max-width: 100%;"}

### (4). 一些补充说明

#### 1). 去噪生成

正如前面所说，NSCN实际上就是在做基于梯度的去噪生成。$$\tilde{x} = x + \sigma \epsilon$$，从而$$\nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x) = -\frac{\epsilon}{\sigma}$$，也就是说，我们希望网络基于输入$$\tilde{x}, \sigma$$所需要学习的$$q_{\sigma}(\tilde{x} \vert x)$$的分数，即$$s_{\theta}(\tilde{x}, \sigma) = \nabla_{\tilde{x}} log q_{\sigma}(\tilde{x} \vert x)$$，**与所加噪声的方向相反**（注意$$\tilde{x}, x, \epsilon$$都是高维数据，可以近似地看作高维向量）。因此，在采样生成的时候，沿着分数的方向走，就是沿着噪声的反方向走，这样就能够最终回到最初的未加上噪声的样本，也就是去噪！

#### 2). 与DDPM的关系

NCSN和DDPM一样，本质都是去噪，前者是隐式的，后者是显式的，NCSN所用的denoising score matching算法所使用的目标函数DSM，实际上就是在预测噪声，而DDPM的反向扩散过程，就是希望模型直接预测所加的噪声。


## 3. 关于DDPM和NCSN的总结

生成模型的本质，就是对数据的概率密度分布进行拟合，从而实现采样。而如何表示概率分布，不同模型有不同的办法，可被分为两种范式：（1）对数据的采样过程建模；（2）对数据的概率密度建模。前者并不纠结于数据分布的概率密度，而是通过其他方式达到表示概率分布的目的，因此被称为隐式模型（implicit）。而后者直接让模型估计概率密度，于是被称为显式模型（explicit）。

隐式模型里最有名的就是GAN，其对网络框架没有限制，但是其训练不稳定，无法计算似然函数，并且没有一个统一的标准来衡量模型的优劣。

显式生成模型包括贝叶斯网络（比如VAE），马尔可夫随机场，自回归模型，flow models等，这类模型也叫做似然模型，其通过最大似然的方式来学习数据分布。这类模型的首要优点是可以计算似然，从而能够很容易的衡量模型的优劣，但是使用一般的energy-based模型来表示概率，需要归一化参数，这限制了模型的灵活性（因为需要选择能够学习归一化参数的模型框架）。

从本质上来说，DDPM也是显式生成模型，其可以看作级联的VAE，其使用的训练目标也是极大似然，并且其对似然函数的处理方式也类似于VAE里的变分推理法。但是DDPM在扩散的过程中，每一步都走的很小，这样使得模型的训练更加容易以及稳定，从而效果会更好，但付出了时间长的代价。

而分数模型则与之前所说的生成模型都不一样，其是估计数据分布的对数的梯度（即score），利用所估计的score使用朗之万采样获取新数据。而NCSN是分数模型的一种，其通过给数据加上不同强度的噪声，然后训练网络去联合估计加噪后的数据分布的score，来使得网络能够近似原未加噪数据的score。

> 这里的联合估计，指的是对于加上了不同级别噪声的数据的分数，用同样的一个网络去估计。而且注意，网络估计的是加噪的数据分布的分数，并不是原始数据分布的分数，原始数据分布的分数在网络经过充分的学习之后可以进行近似。

**参考文献**
* https://yang-song.net/blog/2021/score/
* https://zhuanlan.zhihu.com/p/670052757
* https://zhuanlan.zhihu.com/p/662633920
* https://zhuanlan.zhihu.com/p/597490389
