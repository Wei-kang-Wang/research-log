---
layout: post
comments: True
title: "扩散模型（一）：基于DDPM的解释"
date: 2024-01-01 01:09:00
tags: diffusion

---

<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---

Diffusion models可以说是现如今机器学习领域最火的模型，其不仅在生成模型领域性能上大大超越了之前的那些前辈们，包括GAN，VAE，flow-based模型等，还在多模态领域也引起了革命，比如StableDiffusion等。而且由于diffusion模型，尤其是结合文本和图像的多模态diffusion模型，其所学习到的feature具有很好的semantics可解释性，所以pre-trained好的diffusion模型现在也被用于很多任务之中，最火的比如说基于diffusion模型loss改进的score distillation sampling (SDS)的各种diffusion-based 3D representation learning（比如DreamFusion，Magic3D，zero-1-to-3等）都具有惊艳的效果。而本文，则从原理到应用到代码，综合的介绍一下diffusion models，这个如今AI领域的核心模型。

在开始正式的介绍之前，首先来看看diffusion model和之前的那些生成模型的对比。

![1]({{ '/assets/images/diffusion_1.png' | relative_url }}){: width=800px style="float:center"} 

GAN的缺点在于比较难以训练（discriminator过好的话，generator更新的梯度会很小，训练不动，而discriminator过差的话，generator的更新梯度方向就是错误的，训练结果不对。即使是后续改进的Wasserstein GAN也没有完全解决这个问题）。而VAE的缺点在于需要假设分布是简单的（比如高斯分布），否则难以求解。而flow-based模型则需要transformation functions是invertible的，也限制了模型的flexibility。

而diffusion模型不同于之前的生成模型范式，提出了个新的框架，其受到了物理学里的non-equilibrium thermodynamics的启发，简单举个例子，在水中滴入墨水，那么墨水就会逐渐扩散到整杯水都会变黑。diffusion模型的思路就是，在”干净“的原输入数据（比如说图片）上逐渐加上噪声，一般来说就是0均值的高斯噪声，每一步都是在前一次的基础上再往上添加。如果能够控制好这些高斯噪声的方差大小的话，理论上足够长的时间，我们就可以得到一个均值为0，方差为1的标准高斯分布了（这样说不太准确，因为最终得到的是一个被污染了的数据，准确来说是，最终我们得到的这个被污染的数据，其分布服从均值为0，方差为1的高斯分布）。但我们想要的并不是高斯噪声，我们想要的是能生成和输入数据”长得像“的新的干净的数据。而diffusion模型的做法是，从一个均值为0，方差为1的高斯分布出发，采样一个值，然后逐步让一个Denoiser来将这个值里的噪声逐步去除掉，也就是将之前的加噪声的过程逆过来，如果这个逆过程能够很好的模拟之前的添加噪声的逆过程，那么很多步之后，我们就应该能够得到去除掉噪声的干净的数据了。因为这个去噪过程的输入是随即从标准高斯分布采样的值，所以具有随机性，从而这样得到的干净的数据也是具有随机性的，也就是说每次采样都可以有不同的生成数据输出了。上述这两个过程，就分别叫做diffusion model的前向过程，和反向过程，也叫做加噪过程和去噪过程。

![2]({{ '/assets/images/diffusion_2.png' | relative_url }}){: width=800px style="float:center"} 

一般情况下，上述过程里的denoiser，由一个神经网络来实现。对于每个”干净“的输入图片$$x_0$$，先采样一个时间$$t$$，然后给$$x_0$$添加噪声，这个噪声的大小和$$t$$有关，然后将加噪后的数据，以及$$t$$，同时输入给denoiser，其输出和$$x_0$$之间的差别，就是整个训练的loss。

介绍diffusion模型的博客和论文很多，而最重要的是提出diffusion模型的两篇论文：[DDPM](https://arxiv.org/pdf/2006.11239)和[NCSN](https://arxiv.org/pdf/1907.05600)，这两篇论文分别从不同的角度介绍了diffusion模型，也是接下来理论介绍diffusion模型的两个角度。

这是一些有关Diffusion模型的博客：
* Diffusion is spectral autoregression: https://sander.ai/2024/09/02/spectral-autoregression.html
* Perspectives on diffusion: https://sander.ai/2023/07/20/perspectives.html

如之前所说，diffusion模型可以从两个角度来理解其原理，其中DDPM（diffusion  probabilistic models）的解释更容易理解，从而先从此角度来说。

## 1. 前向扩散过程（forward diffusion process）

从一个给定的数据分布$$q(x)$$里采样一个数据$$x_0$$，$$x_0 \sim q(x)$$（$$x_0$$就可以被理解为我们手里已有的数据，而$$q(x)$$是已有的数据潜在的数据分布，是未知的），扩散模型的一个前向扩散过程，就是不断地给数据添加高斯噪声的过程，假设一共添加了$$T$$步，那么就会得到一系列noisy的数据：$$x_1, x_2, \cdots, x_T$$，而每一步具体添加多少噪声，则是由一组超参数$$\lbrace \beta_t \in (0,1) \rbrace_{t=1}^T$$决定的:

$$q(x_t \vert x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t \mathbf{I}), \  \text{where} \  t=1,2,\cdots,T$$

可以看出来，$$x_0, x_1, \cdots, x_T$$是个马尔可夫链，从而$$x_1, \cdots, x_T$$在$$x_0$$条件下的联合分布就可以写成如下形式：

$$q(x_{1:T} \vert x_0) = \Pi_{t=1}^T q(x_t \vert x_{t-1})$$

原本“干净”的数据$$x_0$$，随着时间的推进，增加的噪声越来越多，逐渐就失去了原本的structure，在合适的$$\lbrace \beta_t \in (0,1) \rbrace_{t=1}^T$$的设置下，以及$$T \rightarrow \infty$$的情况下，$$x_T \sim \mathcal{N}(0, \mathbf{I})$$。

而实际上，前向过程的一个良好的性质是，我们可以得到$$x_t$$与$$x_0$$的closed form的关系（$$1 \leq t \leq T$$）：

记$$\alpha_t = 1 - \beta_t$$，$$\bar{\alpha}_t = \Pi_{i=1}^t \alpha_i$$，那么：

$$
\begin{align}

x_t &= \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&= \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-1} + \sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_t}\epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + (\sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_t}\epsilon_{t-1}) \\
&= \sqrt{\alpha_t \alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_{t}\alpha_{t-1}}\bar{\epsilon}_2, \  \text{where} \  \bar{\epsilon}_2 \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&= \cdots \\
&= \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \bar{\epsilon}_t, \  \text{where} \  \bar{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
\end{align}
$$

上述推导用到了一个结论：$$x \sim \mathcal{N}(\mathbf{0}, \sigma_1^2 \mathbf{I}), y \sim \mathcal{N}(\mathbf{0}, \sigma_2^2 \mathbf{I})$$，那么$$x+y \sim \mathcal{N}(\mathbf{0}, (\sigma_1^2 + \sigma_2^2) \mathbf{I})$$。

上述过程的第一行里，$$x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$用到了一个重参数化技巧（reparametrization trick），将$$x_t$$的随机性，转移到了$$\epsilon_{t-1}$$上，而$$\epsilon_{t-1}$$是从一个无可学习参数的标准高斯分布采样来的。这样做的好处是，因为在计算loss反向传播的时候，需要计算loss对于$$x_t$$的导数，如果$$x_t$$是采样来的，采样过程是离散的而且不可导，这样就没法算了。

由上述推导，可以得到在$$x_0$$条件下$$x_t$$的分布是个高斯分布：

$$q(x_t \vert x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}x_0, (1 - \bar{\alpha}_t)\mathbf{I})$$

一般来说，对于超参数$$\lbrace \beta_t \in (0,1) \rbrace_{t=1}^T$$的设置是，随着$$t$$的增大，噪声的程度可以越来越大，也就是说$$\beta_1 < \beta_2 < \cdots < \beta_T$$，从而$$\alpha_1 > \alpha_2 > \cdots > \alpha_T$$，且$$\bar{\alpha}_1 > \bar{\alpha}_2 > \cdots > \bar{\alpha}_T$$。

## 2. 反向扩散过程（reverse diffusion process）

如果我们可以建模上述前向扩散过程的逆过程，也就是建模$$q(x_{t-1} \vert x_t)$$的话，那么基于一个从标准高斯分布采样得到的纯噪声数据$$x_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$，就可以一步步回退，逐步去除噪声，最终得到一个新的”干净“的$$x_0$$，而因为$$x_T$$的采样是具有随机性的，所以每次得到的$$x_0$$也不一样，这样就可以源源不断地生成”干净“的数据了。

我们有如下结论：如果$$\beta_t$$足够小的话，那么如果$$q(x_t \vert x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t \mathbf{I})$$是个高斯分布，那么$$q(x_{t-1} \vert x_t)$$也是个高斯分布。但这个高斯分布的均值和方差无法解析表达。从而我们考虑用一个带有可学习参数$$\theta$$的模型$$p_{\theta}$$来对$$q(x_{t-1} \vert x_t)$$进行建模：

$$p_{\theta}(x_{t-1} \vert x_t) = \mathcal{x_{t-1}; \mu_{\theta}(x_t, t), \Sigma_{\theta}(x_t, t)}$$

我们同样假设反向扩散过程也是个马尔可夫链，也就是说：

$$q(x_{0:T}) = q(x_T) \Pi_{t=1}^T q(x_{t-1} \vert x_t) = q(x_T) \Pi_{t=1}^T p_{\theta}(x_{t-1} \vert x_t)$$

如果我们在分布$$q(x_{t-1} \vert x_t)$$上再加上条件$$x_0$$的话，也就是考虑分布$$q(x_{t-1} \vert x_t, x_0)$$，有如下结果：

$$
\begin{align}

q(x_{t-1} \vert x_t, x_0) &= q(x_t \vert x_{t-1}, x_0) \frac{q(x_{t-1} \vert x_0)}{q(x_t \vert x_0)} = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t \mathbf{I}) \frac{\mathcal{N}(x_{t-1}; \sqrt{\bar{\alpha}_{t-1}}x_0, (1-\bar{\alpha}_{t-1})\mathbf{I})}{\mathcal{N}(x_{t}; \sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)\mathbf{I})}\\
& \propto exp(-\frac{1}{2} \frac{(x_t - \sqrt{\alpha_t} x_{t-1})^T(x_t - \sqrt{\alpha_t} x_{t-1})}{\beta_t} + \frac{1}{2} \frac{(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_{0})^T(x_{t-1} - \sqrt{\bar{\alpha}_{t-1}} x_{0})}{1 - \bar{\alpha}_{t-1}}) - \frac{1}{2} \frac{(x_{t} - \sqrt{\bar{\alpha}_t} x_{0})^T(x_{t} - \sqrt{\bar{\alpha}_t} x_{0})}{1 - \bar{\alpha}_t})\\
&= exp(-\frac{1}{2}((\frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar{\alpha_{t-1}}})x_{t-1}^Tx_{t-1} - (\frac{2 \sqrt{\alpha_t}}{\beta_t}x_t^T + \frac{2 \sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}x_0^T)x_{t-1})+ C(x_0, x_t)), \  \text{where} \  C(x_0, x_t) \  \text{is} \  \text{a} \  \text{constant} \  \text{w.r.t.} \  x_{t-1}
\end{align}
$$

从这个形式可以看出，$$q(x_{t-1} \vert x_t, x_0)$$也满足高斯分布，$$q(x_{t-1} \vert x_t, x_0) = \mathcal{N}(x_{t-1} \vert \tilde{\mu}(x_t, x_0), \tilde{\beta_t} \mathbf{I})$$，其中

$$\tilde{\beta_t} = 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar{\alpha}_{t-1}}) = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t, \tilde{\mu}(x_t, x_0) = (\frac{2 \sqrt{\alpha_t}}{\beta_t}x_t + \frac{2 \sqrt{\bar{\alpha_{t-1}}}}{1-\bar{\alpha_{t-1}}}x_0) / (\frac{\alpha_t}{\beta_t} + \frac{1}{1-\bar{\alpha}_{t-1}}) = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}x_0$$

而之前我们有结论：$$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \bar{\epsilon}_t, \  \text{where} \  \bar{\epsilon}_t \sim \mathcal{N}(\textbf{0}, \textbf{I})$$，也就是，$$x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\bar{\epsilon}_t)$$，带入$$\tilde{\mu}(x_t, x_0)$$上面的结果，可得：$$\tilde{\mu}(x_t, x_0) = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t)$$，与$$x_0$$无关了，因此也可以记为$$\tilde{\mu}_t$$。

上述的推导过程表明，$$q(x_{t-1} \vert x_t, x_0)$$可以有closed-form的结果。先把这个结果放在一旁。

## 3. 损失函数

既然我们希望用一个带参数的分布$$p_{\theta}$$来对$$q(x_{t-1} \vert x_t)$$进行近似，那么我们就需要定义损失函数来让$$p_{\theta}$$与$$q(x_{t-1} \vert x_t)$$尽可能靠近，如下的推导对$$p_{\theta}$$的形式不做任何假设。

我们可以发现，实际上$$p_{\theta}(x_{t-1} \vert x_t)$$很像VAE里的$$q_{\phi}(z \vert x)$$，而$$q(x_{t-1} \vert x_t)$$则是VAE的decoder的未知后验分布$$p_{\theta}(z \vert x)$$（这里的$$\theta$$和之前的$$\theta$$不一样，这里指的是VAE里的分布）。从而根据这个观察，我们也可以仿照VAE的损失函数，定义如下的损失函数：

$$
\begin{align}
-log p_{\theta}(x_0) &\leq -log p_{\theta}(x_0) + \textbf{D}_{\textbf{KL}} (q(x_{1:T} \vert x_0) \Vert p_{\theta}(x_{1:T} \vert x_0)) = -log p_{\theta}(x_0) + \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{1:T} \vert x_0)} \right] \\
&= -log p_{\theta}(x_0) + \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{0:T})} + log p_{\theta}(x_0) \right] = \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{0:T})} \right]
\end{align}
$$

对上个式子两侧以$$q(x_0)$$为分布取期望，则有：

$$ - \mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log p_{\theta}(x_0) \right] \leq \mathop{\mathbb{E}}\limits_{q(x_{0:T})} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{0:T})} \right]$$

记上面式子的右侧为$$\mathcal{L}_{VLB}$$。

我们再来考虑$$q(x_0)$$和$$p_{\theta}(x_0)$$之间的cross entropy：

$$
\begin{align}
\mathcal{L}_{CE} &= -\mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log p_{\theta}(x_0) \right] = -\mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log \int p_{\theta}(x_{0:T}) dx_{1:T} \right] = -\mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log \int q(x_{1:T} \vert x_0) \frac{p_{\theta}(x_{0:T})}{q(x_{1:T} \vert x_0)} dx_{1:T} \right] \\
&= -\mathop{\mathbb{E}}\limits_{q(x_0)} \left[ log -\mathop{\mathbb{E}}\limits_{q(x_{1:T} \vert x_0)} (\frac{p_{\theta}(x_{0:T})}{q(x_{1:T} \vert x_0)}) \right] \leq -\mathop{\mathbb{E}}\limits_{q(x_0)} \mathop{\mathbb{E}}\limits_{q(x_{1:T} \vert x_0)} log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T} \vert x_0)} = - \mathop{\mathbb{E}}\limits_{q(x_{0:T} \vert x_0)} log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T} \vert x_0)} = \mathcal{L}_{VLB}
\end{align}
$$

回到之前的结果：$$-log p_{\theta}(x_0) \leq \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_{1:T} \vert x_0)}{p_{\theta}(x_{0:T})} \right]$$，记右侧这个式子为$$\mathcal{L}_{VLB}^{\ast}$$，也就是说，$$\mathcal{L}_{VLB} = \mathop{\mathbb{E}}\limits_{q(x_0)} \left[ \mathcal{L}_{VLB}^{\ast} \right]$$，那么：

$$
\begin{align}
\mathcal{L}_{VLB}^{\ast} &= \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{\Pi_{t=1}^T q(x_t \vert x_{t-1})}{p_{\theta}(x_T) \Pi_{t=1}^T p_{\theta}(x_{t-1} \vert x_t)} \right] = \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ -log p_{\theta}(x_T) + \sum_{t=2}^T log(\frac{q(x_t \vert x_{t-1})}{p_{\theta}(x_{t-1} \vert x_t)}) + log \frac{q(x_1 \vert x_0)}{p_{\theta}(x_0 \vert x_1)} \right] \\
&= \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ -log p_{\theta}(x_T) + \sum_{t=2}^T log(\frac{q(x_t \vert x_{t-1}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) + log \frac{q(x_1 \vert x_0)}{p_{\theta}(x_0 \vert x_1)} \right] = \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ -log p_{\theta}(x_T) + \sum_{t=2}^T log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}\frac{q(x_t \vert x_0)}{q(x_{t-1} \vert x_0)}) + log \frac{q(x_1 \vert x_0)}{p_{\theta}(x_0 \vert x_1)} \right] \\
&= \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ -log p_{\theta}(x_T) + \sum_{t=2}^T log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) + \sum_{t=2}^T log (\frac{q(x_t \vert x_0)}{q(x_{t-1} \vert x_0)}) + log \frac{q(x_1 \vert x_0)}{p_{\theta}(x_0 \vert x_1)} \right] = \mathop{\mathbb{E}}\limits_{x_{1:T} \sim q(x_{1:T} \vert x_0)} \left[ log \frac{q(x_T \vert x_0)}{p_{\theta}(x_T)} - log p_{\theta}(x_0 \vert x_1) + \sum_{t=2}^T log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) \right] \\
&= -\mathop{\mathbb{E}}\limits_{x_1 \sim q(x_1 \vert x_0)} \left[ log p_{\theta}(x_0 \vert x_1) \right] + \mathop{\mathbb{E}}\limits_{x_T \sim q(x_T \vert x_0)} \left[ log \frac{q(x_T \vert x_0)}{p_{\theta}(x_T)} \right] + \sum_{t=2}^T \mathop{\mathbb{E}}\limits_{x_{t-1}, x_t \sim q(x_{t-1}, x_t \vert x_0)} \left[ log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) \right]\\
&= -\mathop{\mathbb{E}}\limits_{x_1 \sim q(x_1 \vert x_0)} \left[ log p_{\theta}(x_0 \vert x_1) \right] + \textbf{D}_{\textbf{KL}}(q(x_T \vert x_0) \Vert p(x_T)) + \sum_{t=2}^T \mathop{\mathbb{E}}\limits_{x_{t-1}, x_t \sim q(x_t \vert x_0)q(x_{t-1} \vert x_t, x_0)} \left[ log(\frac{q(x_{t-1} \vert x_{t}, x_0)}{p_{\theta}(x_{t-1} \vert x_t)}) \right] \\
&= -\mathop{\mathbb{E}}\limits_{x_1 \sim q(x_1 \vert x_0)} \left[ log p_{\theta}(x_0 \vert x_1) \right] + \textbf{D}_{\textbf{KL}}(q(x_T \vert x_0) \Vert p(x_T)) + \sum_{t=2}^T \mathop{\mathbb{E}}\limits_{x_t \sim q(x_t \vert x_0)} \left[ \textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_{t}, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) \right]
\end{align}
$$

其中，上面式子右侧第一项叫做reconstruction term，第二项叫做prior matching term，第三项叫做denoising matching term。

denoising matching term里的每一项，由之前的结果可知：

$$q(x_{t-1} \vert x_t, x_0) = \mathcal{N}(x_{t-1}; \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t), \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t)$$

为了让$$p_{\theta}(x_{t-1} \vert x_t)$$和$$q(x_{t-1} \vert x_t, x_0)$$之间的$$DL$$散度尽可能小，我们则也假设$$p_{\theta}(x_{t-1} \vert x_t)$$为高斯分布（与之前的假设不谋而合）。因为我们已经计算出来$$q(x_{t-1} \vert x_t, x_0)$$的方差为$$\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t$$是个常数，所以$$p_{\theta}(x_{t-1} \vert x_t)$$的方差也是该值，但是$$q(x_{t-1} \vert x_t, x_0)$$的均值是$$\frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t)$$，其中$$\bar{\epsilon}_t$$是每次前向扩散过程从标准高斯分布中随机采样的值，这是未知的（因为有$$x_t, x_0, \bar{\epsilon_{t}}$$之间的关系，$$x_t$$在反向扩散过程中是已知的，$$x_0$$是我们希望要得到的，$$x_0$$的未知性和$$\bar{\epsilon}_t$$的未知性等价），所以没办法直接让$$p_{\theta}(x_{t-1} \vert x_t)$$的均值就等于它，从而这就成为了扩散模型需要利用神经网络进行学习的部分，记$$p_{\theta}(x_{t-1} \vert x_t)$$的均值为$$\mu_{\theta}$$。

因为$$p_{\theta}(x_{t-1} \vert x_t)$$和$$q(x_{t-1} \vert x_t, x_0)$$都是高斯分布，实际上它们之间的$$DL$$散度是可以closed-form计算出来的：

$$\textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_t, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) = \frac{1}{2\tilde{\beta_t}} \Vert \mu_{\theta} - \tilde{\mu}_t \Vert_2^2$$

对于reconstruction term，在原论文中用另一个单独的网络来优化，即认为$$p_{\theta^{'}}(x_0 \vert x_1) \sim \mathcal{N}(x_0; \tilde{\mu}_{\theta^{'}}(x_1, t=1), \Sigma_{\theta^{'}}(x_1, t=1))$$。而prior matching term不含可学习参数$$\theta$$。

所以说，最小化$$\mathcal{L}_{VLB}^{\ast}$$（也就是等价于最小化$$\mathcal{L}_{VLB}$$）的重点就在于最小化denoising matching term里的每一项$$p_{\theta}(x_{t-1} \vert x_t)$$和$$q(x_{t-1} \vert x_t, x_0)$$之间的$$DL$$散度，$$2 \leq t \leq T$$。而根据上面的推导过程可知，也就等价于最小化每个高斯分布$$p_{\theta}(x_{t-1} \vert x_t)$$的均值和高斯分布$$q(x_{t-1} \vert x_t, x_0)$$的均值。$$p_{\theta}(x_{t-1} \vert x_t)$$的均值由网络预测出，网络的输入是$$x_t$$和时间$$t$$，而$$q(x_{t-1} \vert x_t, x_0)$$的均值是已知的，有两种写法：

$$\tilde{\mu}(x_t, x_0) = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}x_0$$

$$\tilde{\mu}(x_t, x_0) = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t)$$

从而我们的神经网络输出也可以有两种：（1）输入$$x_t, t$$，预测$$x_0$$；（2）输入$$x_t, t$$，预测$$\bar{\epsilon}_t$$。记$$f_{\theta}(x_t, t)$$为网络的输出。

对于第一种情况：

$$\mu_{\theta} = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}f_{\theta}(x_t, t)$$

从而：

$$\arg\min\limits_{\theta} \textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_{t}, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) = \arg\min\limits_{\theta} \frac{\bar{\alpha}_{t-1}\beta_t^2}{2\tilde{\beta_t} (1-\bar{\alpha}_t)^2} \Vert f_{\theta}(x_t, t) - x_0 \Vert_2^2$$

对于第二种情况：

$$\mu_{\theta} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} f_{\theta}(x_t, t))$$

从而：

$$\arg\min\limits_{\theta} \textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_{t}, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) = \arg\min\limits_{\theta} \frac{1}{2\tilde{\beta_t} \alpha_t} \frac{(1-\alpha_t)^2}{1-\bar{\alpha}_t} \Vert f_{\theta}(x_t, t) - \bar{\alpha}_t \Vert_2^2$$

diffusion模型一般采用第二种方式，因为对噪声进行建模会更加关注细节（噪声相对于原数据$$x_0$$要更小一些）。

在第二种方式下，回到$$\mathcal{L}_{VLB}$$中，则是：

$$
\begin{align}
\arg\min\limits_{\theta} \mathcal{L}_{VLB} &= \arg\min\limits_{\theta} \sum_{t=2}^T  \mathop{\mathbb{E}}\limits_{x_t, x_0 \sim q(x_t, x_0)} \left[ \textbf{D}_{\textbf{KL}}(q(x_{t-1} \vert x_{t}, x_0) \Vert p_{\theta}(x_{t-1} \vert x_t)) \right] = \arg\min\limits_{\theta} \sum_{t=2}^T \mathop{\mathbb{E}}\limits_{x_t, x_0 \sim q(x_t, x_0)} \left[ \frac{\bar{\alpha}_{t-1}\beta_t^2}{2\tilde{\beta_t} (1-\bar{\alpha}_t)^2} \Vert f_{\theta}(x_t, t) - \bar{\epsilon}_t \Vert_2^2 \right] \\
&= \arg\min\limits_{\theta} \mathop{\mathbb{E}}\limits_{x_0 \sim q(x_0), \bar{\epsilon}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{I}), t \sim \left[2, T \right]} \left[\frac{\bar{\alpha}_{t-1}\beta_t^2}{2\tilde{\beta_t} (1-\bar{\alpha}_t)^2} \Vert f_{\theta}(x_t, t) - \bar{\epsilon}_t \Vert_2^2 \right]
\end{align}
$$

所以说反向扩散过程（denoising）过程的本质，在于让模型学会以任意时刻$$t$$时加噪的数据以及时间$$t$$作为输入，都可以学到这个时刻的数据在“干净”数据上所加上的噪声（也就等价于学到“干净”的数据）。

DDPM模型的训练过程如下左图。而在训练完成之后，想要生成数据（采样）的过程如下右图

![3]({{ '/assets/images/diffusion_3.png' | relative_url }}){: width=800px style="float:center"} 


## 4. 一些补充说明

### (1). 关于超参数$$\lbrace \beta_t \in (0,1) \rbrace_{t=1}^T$$的选择

根据假设，$$q(x_t \vert x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t \mathbf{I}), \  \text{where} \  t=1,2,\cdots,T$$。也就是说，$$x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$，但是为什么均值和方差的系数有这样的关系，并没有说明。下面给出一些intuition。

首先，假设$$x_t$$与$$x_{t-1}$$的关系是线性的（因为最简单），即：$$x_t = a_t x_{t-1} + b_t \epsilon_{t-1}, \  \text{where} \  \epsilon_{t-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$$。因为前向扩散过程是个加噪的过程，所以$$x_t$$应该是相对于$$x_{t-1}$$是衰减的，从而$$a_t, b_t \in (0,1)$$。

那么，我们将$$x_t$$的表达式不断地往后迭代，使用$$x_0$$来表示$$x_t$$：

$$x_t = a_t x_{t-1} + b_t \epsilon_{t-1} = a_t a_{t-1} x_{t-2} + a_t b_{t-1} \epsilon_{t-2} + b_t \epsilon_{t-1} = \cdots = (a_t a_{t-1} \cdots a_1) x_0 + (a_t \cdots a_2)b_1 \epsilon_{0} + \cdots + a_t b_{t-1} \epsilon_{t-2} + b_t \epsilon_{t-1}$$

从而，将第二项到最后一项全部综合起来，其也满足一个高斯分布，方差为$$\lbrace (a_t \cdots a_2b_1)^2 + \cdots + (a_t b_{t-1})^2 + (b_t)^2) \mathbf{I}$$。如果再考虑将第一项$$x_0$$的系数的平方和考虑进来，那么此时$$x_0$$系数的平方，与后面的方差的系数的平方和就是：$$(a_t \cdots a_1)^2 + (a_t \cdots a_2b_1)^2 + \cdots + (a_t b_{t-1})^2 + (b_t)^2) = a_t^2(a_{t-1}^2(\cdots(a_2^2(a_1^2+b_1^2)+b_2^2)+\cdots)+b_{t-1}^2)+b_t^2$$。如果令$$a_i^2 + b_i^2 =1$$对于所有的$$1\leq i \leq t$$成立，则该平方和就是1，而此时这些超参数的选择，就是前文所述的。

### (2). 图解DDPM过程

训练过程：

![-1]({{ '/assets/images/diffusion_-1.png' | relative_url }}){: width=800px style="float:center"} 

![0]({{ '/assets/images/diffusion_0.png' | relative_url }}){: width=800px style="float:center"} 

采样过程：

![-2]({{ '/assets/images/diffusion_-2.png' | relative_url }}){: width=800px style="float:center"} 

### (3). DDPM为什么要采样那么多步？

DDPM存在一个非常明显的缺点，就是采样速度过慢，在生成一张图片的过程中，我们需要进行$$T$$次迭代，而一般T都是非常大的（e.g.~1000）。因此DDPM虽然图像的质量和多样性很好，但生成效率非常低。为了解决这个问题，[DENOISING DIFFUSION IMPLICIT MODELS](https://arxiv.org/pdf/2010.02502)提出了一个新的模型（或者称为采样方式）叫做Denoising Diffusion Implicit Models（DDIM）。

DDIM里首先提问，为什么DDPM一定要这么多次采样？加快DDPM的生成效率。最容易想到的两种方法：首先就是减小$$T$$，其次是 “跳步”（i.e. 不再严格按照$$x_{t-1}到$$x_t$$的顺序来采样）。下面依次讨论这两种操作的可行性。

**第一，减小$$T$$是否可行？答案是否定的**

因为在DDPM中，有如下关系：

$$x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{1 - \alpha_t} \epsilon$$

对于每个$$t$$，$$1-\alpha_t$$都需要接近于0，$$\alpha_t$$都需要接近1，这是因为：
 * 只有$$1-\alpha_t$$比较小的时候，才能满足$$q(x_{t-1} \vert x_t)$$也满足近似为高斯分布的假设
 * $$x_{t-1}$$的系数$$\alpha_t$$要尽量接近于1，这束为了保证$$t$$时刻的加噪数据$$x_t$$要尽量保留$$t-1$$时刻的大体分布，如果噪声破坏过大，就难以让模型学习了

同时，我们也有如下关系：

$$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$$

根据DDPM里的假设，我们希望在$$T$$时刻，也就是最后时刻，$$x_T$$是近似于标准正态分布的，也就是说$$\sqrt{\bar{\alpha}_T}$$接近于0，$$\sqrt{1 - \bar{\alpha}_T}$$接近于1。从而在$$\alpha_t, t=1,2,\cdots,T$$都接近于1的条件下，只有$$T$$足够大，才能满足$$\sqrt{\bar{\alpha}_T}$$接近于0。

**第二，为什么一定要从$$x_T$$开始一步步的降噪，即从$$x_t$$到$$x_{t-1}$$，$$t=T, T-1, \cdots, 1$$，能否跳步？答案也是否定的**

首先，能否由$$x_t$$直接得到$$x_s$$（其中$$s<k$$），答案是否定的，因为无法直接得到$$q(x_s \vert x_k)$$的表达式。

根据之前的损失函数的推导，DDPM的优化目标是让$$q(x_{t-1} \vert x_t)$$去近似分布$$q(x_{t-1} \vert x_t, x_0)$$，而后者在前述推导中是通过贝叶斯公式得到closed-form的结果的：

$$q(x_{t-1} \vert x_t, x_0) = \frac{q(x_t \vert x_{t-1})q(x_{t-1} \vert x_0)}{q(x_t \vert x_0)}$$

按照前述的结果，$$q(x_{t-1} \vert x_t, x_0)$$是一个高斯分布，所以$$q(x_{t-1} \vert x_t)$$也需要是一个高斯分布，且均值需要近似于$$q(x_{t-1} \vert x_t, x_0)$$的均值$$\tilde{\mu}(x_t, x_0) = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_t)$$（方差是个常数，可以直接设置为相等）。

而在DDPM中，是利用网络来近似这个均值的（近似$$x_0$$或者近似$$\bar{\epsilon}_t$$，注意到$$x_0$$和$$x_t$$之间有$$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$$）：

$$\mu_{\theta} = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}f_{\theta}(x_t, t)$$

或者

$$\mu_{\theta} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} f_{\theta}(x_t, t))$$

但不管是哪种方式，其近似的都是分布$$q(x_{t-1} \vert x_t)$$的均值，而如果将分布$$q(x_{t-1} \vert x_t)$$改成别的形式，比如$$q(x_{s} \vert x_t)$$（其中$$s < k$$），我们就没有上面的那些推导的结果了。

其次，那能否直接由$$x_t$$得到$$x_0$$？

答案是可以的，$$x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \sqrt{1-\bar{\alpha}_t} \bar{\epsilon}_t)$$，而网络正好是预测$$\bar{\epsilon}_t$$的值的，即：$$f_{\theta}(x_t, t) \approx \bar{\epsilon}_t$$，从而可以直接由$$x_t$$得到$$x_0$$：

$$x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(x_t - \sqrt{1-\bar{\alpha}_t} f_{\theta}(x_t, t))$$

实际上，上述操作也就等价于在设计网络的时候，让网络对于不同的加噪数据$$x_t$$和timestep $$t$$输入，输出$$x_0$$，而并非输出噪声估计$$\bar{\epsilon}_t$$。

但为何在实际操作中不这么做，原因只有一个，就是实验表明这样操作生成效果差。

上述具体解释在[DDPM的原论文](https://hojonathanho.github.io/diffusion/assets/denoising_diffusion20.pdf)里也有说明（section 3.2）：

> To summarize, we can train the reverse process mean function approximator \textbf{\mu}_{\theta} to predict $$\mu_t$$, or by modifying its parameterization, we can train it to predict $$\epsilon_t$$. (**There is also the possibility of predicting $$x_0$$, but we found this to lead to worse sample quality early in our experiments.**) We have shown that the $$epsilon$$-prediction parameterization both resembles Langevin dynamics and simplifies the diffusion model’s variational bound to an objective that resembles denoising score matching. Nonetheless, it is just another parameterization of $$p_{\theta}(x_{t-1} \vert x_t)$$, so we verify its effectiveness in Section 4 in an ablation where we compare predicting $$\epsilon_t$$ against predicting $$\mu_t$$.

**参考文献**
* https://lilianweng.github.io/posts/2021-07-11-diffusion-models/
* https://zhuanlan.zhihu.com/p/565901160
* https://zhuanlan.zhihu.com/p/708195611 

### (5). 代码

* [https://github.com/xiaohu2015/nngen/blob/main/models/diffusion_models/ddpm_mnist.ipynb](https://github.com/xiaohu2015/nngen/blob/main/models/diffusion_models/ddpm_mnist.ipynb)提供了不错的基于DDPM的diffusion models的pytorch实现。
* [https://github.com/lucidrains/denoising-diffusion-pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch)也提供了一个代码实现。
* [https://github.com/nmwsharp/diffusion-net](https://github.com/nmwsharp/diffusion-net)也提供了一个代码实现。
